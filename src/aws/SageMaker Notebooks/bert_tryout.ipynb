{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Try-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 26.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.10.19)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.20.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.36.1)\n",
      "Collecting regex (from pytorch-pretrained-bert)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
      "\u001b[K    100% |████████████████████████████████| 675kB 24.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.15.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.19 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (1.13.19)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->pytorch-pretrained-bert) (0.14)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->pytorch-pretrained-bert) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.19->boto3->pytorch-pretrained-bert) (1.11.0)\n",
      "Building wheels for collected packages: regex\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
      "Successfully built regex\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: regex, pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting livelossplot\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/f6/0618c30078f9c1e4b2cd84f1ea6bb70c6615070468b75b0d934326107bcd/livelossplot-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from livelossplot) (3.0.3)\n",
      "Requirement already satisfied: notebook in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from livelossplot) (5.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->livelossplot) (1.15.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->livelossplot) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->livelossplot) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->livelossplot) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (2.10)\n",
      "Requirement already satisfied: tornado>=4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (5.0.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (5.2.3)\n",
      "Requirement already satisfied: ipython-genutils in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (1.5.0)\n",
      "Requirement already satisfied: ipykernel in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (4.8.2)\n",
      "Requirement already satisfied: nbformat in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (4.4.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (4.3.2)\n",
      "Requirement already satisfied: nbconvert in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (5.4.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (0.8.1)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from notebook->livelossplot) (17.0.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->livelossplot) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (39.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jinja2->notebook->livelossplot) (1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipykernel->notebook->livelossplot) (6.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.8.3)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (2.2.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.2.3)\n",
      "Requirement already satisfied: bleach in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
      "Requirement already satisfied: testpath in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: defusedxml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.12.0)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.4)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.5.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from bleach->nbconvert->notebook->livelossplot) (1.0.1)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.5.2)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.4.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nvidia-ml-py3\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Building wheels for collected packages: nvidia-ml-py3\n",
      "  Running setup.py bdist_wheel for nvidia-ml-py3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "Successfully built nvidia-ml-py3\n",
      "Installing collected packages: nvidia-ml-py3\n",
      "Successfully installed nvidia-ml-py3-7.352.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 26.6MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.1.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert\n",
    "!pip install livelossplot\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install unidecode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import unidecode\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME, BertForMultipleChoice\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.tokenization import (BasicTokenizer,\n",
    "                                                  BertTokenizer,\n",
    "                                                  whitespace_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the IDs of the previous queries of a query in a session \n",
    "def get_lower_ids(session_df, query_id):\n",
    "    session_id = int(query_id.split('_')[0])\n",
    "    current_id = int(query_id.split('_')[1])\n",
    "    all_ids = [int(x.split('_')[1]) for x in session_df['query_id'].tolist()]\n",
    "    lower_ids = [x for x in all_ids if x < current_id]\n",
    "    lower_ids = [str(session_id) + '_' + str(x) for x in lower_ids]\n",
    "    return lower_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that strips all non-alphanumeric characters\n",
    "def remove_non_alphanumeric(text):\n",
    "    text = unidecode.unidecode(str(text))\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a list of segment ids based on indexed tokens (BERT)\n",
    "def get_segment_ids_from_index_tokens(indexed_tokens):\n",
    "    segment_ids = []\n",
    "    sep = False\n",
    "    for i, token in enumerate(indexed_tokens):\n",
    "        if token == 102:\n",
    "            sep = True\n",
    "        if sep:\n",
    "            segment_ids.append(1)\n",
    "        else:\n",
    "            segment_ids.append(0)\n",
    "    return segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bert(data):\n",
    "    activations = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        # convert inputs to PyTorch tensors\n",
    "        tokens = data.iloc[i]['indexed_tokens']\n",
    "        segment_ids = data.iloc[i]['segment_ids']\n",
    "        \n",
    "        # make sure the input fits\n",
    "        token_size_diff = len(tokens) - 512\n",
    "        if token_size_diff > 0:\n",
    "            tokens = [tokens[0]] + tokens[token_size_diff:]\n",
    "            segment_ids = [segment_ids[0]] + segment_ids[token_size_diff:]\n",
    "\n",
    "        tokens_tensor = torch.tensor([tokens])\n",
    "        segments_tensors = torch.tensor([segment_ids])\n",
    "\n",
    "        # set everything to run on GPU\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        segments_tensors = segments_tensors.to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = bertmodel(tokens_tensor, segments_tensors) \n",
    "            activations.append(prediction)\n",
    "\n",
    "    data['pooled_output'] = activations\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"../data/models/\"\n",
    "msmarco_dir = \"../data/msmarco_files/\"\n",
    "anserini_output_dir = \"../data/anserini_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSMARCO collection\n",
    "msmarco_collection = pd.read_csv(msmarco_dir + 'collection.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "msmarco_collection.columns = ['passage_id', 'passage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_subset = pd.read_csv(msmarco_dir + 'queries.train.subset.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "query_subset.columns = ['query_id', 'query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_anserini_output = pd.read_csv(anserini_output_dir + 'run_queries_subset.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "query_anserini_output.columns = ['query_id', 'passage_id', 'bm25_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>passage_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413367</td>\n",
       "      <td>670475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  passage_id  bm25_rank\n",
       "0    413367      670475          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_anserini_output.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make BERT Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c905e26d2fd40258d167882fce20fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8086564), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff6acc36c564c1eabcc69ab6884c999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8086564), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "bert_df = query_anserini_output.copy()\n",
    "bert_df = bert_df.merge(query_subset,how='left',on=['query_id'])\n",
    "bert_df = bert_df.merge(msmarco_collection,how='left',on=['passage_id'])\n",
    "bert_df['query'] = bert_df['query'].progress_apply(lambda x: remove_non_alphanumeric(x.lower()))\n",
    "tqdm.pandas()\n",
    "bert_df['passage'] = bert_df['passage'].progress_apply(lambda x: remove_non_alphanumeric(x.lower()))\n",
    "bert_df['input_text'] = \"[CLS] \" + bert_df['query'] +\" [SEP] \" + bert_df['passage'] + \" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>passage_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413367</td>\n",
       "      <td>670475</td>\n",
       "      <td>1</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cold cut combo   5 50  footlong  italian b m t...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413367</td>\n",
       "      <td>4359509</td>\n",
       "      <td>2</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cheese  amount on 6 inch sandwich  double valu...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>413367</td>\n",
       "      <td>7279276</td>\n",
       "      <td>3</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>footlong chicken   bacon ranch melt  with mayo...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413367</td>\n",
       "      <td>5821389</td>\n",
       "      <td>4</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>calories in a footlong italian b m t  there ar...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>413367</td>\n",
       "      <td>2340426</td>\n",
       "      <td>5</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cheese  amount on 6 inch sandwich  double valu...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  passage_id  bm25_rank                           query  \\\n",
       "0    413367      670475          1  is it a footlong and them some   \n",
       "1    413367     4359509          2  is it a footlong and them some   \n",
       "2    413367     7279276          3  is it a footlong and them some   \n",
       "3    413367     5821389          4  is it a footlong and them some   \n",
       "4    413367     2340426          5  is it a footlong and them some   \n",
       "\n",
       "                                             passage  \\\n",
       "0  cold cut combo   5 50  footlong  italian b m t...   \n",
       "1  cheese  amount on 6 inch sandwich  double valu...   \n",
       "2  footlong chicken   bacon ranch melt  with mayo...   \n",
       "3  calories in a footlong italian b m t  there ar...   \n",
       "4  cheese  amount on 6 inch sandwich  double valu...   \n",
       "\n",
       "                                          input_text  \n",
       "0  [CLS] is it a footlong and them some [SEP] col...  \n",
       "1  [CLS] is it a footlong and them some [SEP] che...  \n",
       "2  [CLS] is it a footlong and them some [SEP] foo...  \n",
       "3  [CLS] is it a footlong and them some [SEP] cal...  \n",
       "4  [CLS] is it a footlong and them some [SEP] che...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:22<00:00, 18372975.98B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', 2)\n",
    "bertmodel.load_state_dict(torch.load(models_dir + 'fine_tuned_bert_base_uncased'))\n",
    "\n",
    "bertmodel.eval()\n",
    "bertmodel.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 1084499.08B/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_bert_df = bert_df[:100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e8e8d2340a431f925a461738e661aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "small_bert_df['indexed_tokens'] = small_bert_df.progress_apply(lambda row: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(row['input_text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589c8bace9454275aabaec377aea798b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "small_bert_df['segment_ids'] = small_bert_df.progress_apply(lambda row: get_segment_ids_from_index_tokens(row['indexed_tokens']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad29341d2edc4fb486169ac8ec257bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_df = run_bert(small_bert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>passage_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>input_text</th>\n",
       "      <th>indexed_tokens</th>\n",
       "      <th>segment_ids</th>\n",
       "      <th>pooled_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>413367</td>\n",
       "      <td>8631041</td>\n",
       "      <td>96.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>magpie faq  birdwatch  received more queries a...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] mag...</td>\n",
       "      <td>[101, 2003, 2009, 1037, 3329, 10052, 1998, 206...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[tensor(3.5071, device='cuda:0'), tensor(-4.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>413367</td>\n",
       "      <td>3835076</td>\n",
       "      <td>97.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>then for the unclean person they shall take so...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] the...</td>\n",
       "      <td>[101, 2003, 2009, 1037, 3329, 10052, 1998, 206...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[tensor(3.5581, device='cuda:0'), tensor(-4.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>413367</td>\n",
       "      <td>4662852</td>\n",
       "      <td>98.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it depends on how you categorize them  for ins...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] it ...</td>\n",
       "      <td>[101, 2003, 2009, 1037, 3329, 10052, 1998, 206...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[tensor(3.4378, device='cuda:0'), tensor(-4.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>413367</td>\n",
       "      <td>4951657</td>\n",
       "      <td>99.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>a 100g of raw watermelon fruit contains    ...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP]    ...</td>\n",
       "      <td>[101, 2003, 2009, 1037, 3329, 10052, 1998, 206...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[tensor(3.5575, device='cuda:0'), tensor(-4.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>413367</td>\n",
       "      <td>6515568</td>\n",
       "      <td>100.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>if you ve decided to start a small farm busine...</td>\n",
       "      <td>[CLS] is it a footlong and them some [SEP] if ...</td>\n",
       "      <td>[101, 2003, 2009, 1037, 3329, 10052, 1998, 206...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[tensor(3.5080, device='cuda:0'), tensor(-4.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id  passage_id  bm25_rank                           query  \\\n",
       "95    413367     8631041       96.0  is it a footlong and them some   \n",
       "96    413367     3835076       97.0  is it a footlong and them some   \n",
       "97    413367     4662852       98.0  is it a footlong and them some   \n",
       "98    413367     4951657       99.0  is it a footlong and them some   \n",
       "99    413367     6515568      100.0  is it a footlong and them some   \n",
       "\n",
       "                                              passage  \\\n",
       "95  magpie faq  birdwatch  received more queries a...   \n",
       "96  then for the unclean person they shall take so...   \n",
       "97  it depends on how you categorize them  for ins...   \n",
       "98     a 100g of raw watermelon fruit contains    ...   \n",
       "99  if you ve decided to start a small farm busine...   \n",
       "\n",
       "                                           input_text  \\\n",
       "95  [CLS] is it a footlong and them some [SEP] mag...   \n",
       "96  [CLS] is it a footlong and them some [SEP] the...   \n",
       "97  [CLS] is it a footlong and them some [SEP] it ...   \n",
       "98  [CLS] is it a footlong and them some [SEP]    ...   \n",
       "99  [CLS] is it a footlong and them some [SEP] if ...   \n",
       "\n",
       "                                       indexed_tokens  \\\n",
       "95  [101, 2003, 2009, 1037, 3329, 10052, 1998, 206...   \n",
       "96  [101, 2003, 2009, 1037, 3329, 10052, 1998, 206...   \n",
       "97  [101, 2003, 2009, 1037, 3329, 10052, 1998, 206...   \n",
       "98  [101, 2003, 2009, 1037, 3329, 10052, 1998, 206...   \n",
       "99  [101, 2003, 2009, 1037, 3329, 10052, 1998, 206...   \n",
       "\n",
       "                                          segment_ids  \\\n",
       "95  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "96  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "97  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "98  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "99  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                        pooled_output  \n",
       "95  [[tensor(3.5071, device='cuda:0'), tensor(-4.4...  \n",
       "96  [[tensor(3.5581, device='cuda:0'), tensor(-4.5...  \n",
       "97  [[tensor(3.4378, device='cuda:0'), tensor(-4.2...  \n",
       "98  [[tensor(3.5575, device='cuda:0'), tensor(-4.5...  \n",
       "99  [[tensor(3.5080, device='cuda:0'), tensor(-4.5...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5bcb704c294d7cb57378d3989bb466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_df['score_bert'] = output_df.progress_apply(lambda row: row['pooled_output'].data[0][1].item(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded columns\n",
    "output_df = output_df.drop(columns=['input_text', 'indexed_tokens', 'segment_ids', 'pooled_output'])\n",
    "\n",
    "# assign a rank to the scores\n",
    "output_df[\"bert_rank\"] = output_df.groupby(\"query_id\")[\"score_bert\"].rank(ascending=0,method='dense')\n",
    "output_df[\"bert_rank\"] = output_df['bert_rank'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>passage_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>score_bert</th>\n",
       "      <th>bert_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413367</td>\n",
       "      <td>670475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cold cut combo   5 50  footlong  italian b m t...</td>\n",
       "      <td>-3.164047</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413367</td>\n",
       "      <td>4359509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cheese  amount on 6 inch sandwich  double valu...</td>\n",
       "      <td>-3.241947</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>413367</td>\n",
       "      <td>7279276</td>\n",
       "      <td>3.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>footlong chicken   bacon ranch melt  with mayo...</td>\n",
       "      <td>-3.161703</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413367</td>\n",
       "      <td>5821389</td>\n",
       "      <td>4.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>calories in a footlong italian b m t  there ar...</td>\n",
       "      <td>-3.973064</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>413367</td>\n",
       "      <td>2340426</td>\n",
       "      <td>5.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cheese  amount on 6 inch sandwich  double valu...</td>\n",
       "      <td>-3.364845</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>413367</td>\n",
       "      <td>6756670</td>\n",
       "      <td>6.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>footlong quarter pound coney  this sonic class...</td>\n",
       "      <td>-2.786904</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>413367</td>\n",
       "      <td>3179620</td>\n",
       "      <td>7.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>unhealthiest options on the subway menu  1  fo...</td>\n",
       "      <td>-3.985879</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>413367</td>\n",
       "      <td>2240246</td>\n",
       "      <td>8.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it should be  10 99 a foot  but it depends on ...</td>\n",
       "      <td>1.892739</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>413367</td>\n",
       "      <td>1243418</td>\n",
       "      <td>9.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>news  subway april 2014 featured  5 footlong  ...</td>\n",
       "      <td>-2.421246</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>413367</td>\n",
       "      <td>2240245</td>\n",
       "      <td>10.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>how much is a 3ft subway sandwich  it should b...</td>\n",
       "      <td>-2.166980</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>413367</td>\n",
       "      <td>6756672</td>\n",
       "      <td>11.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>now you can get approximately twice the sodium...</td>\n",
       "      <td>-3.688279</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>413367</td>\n",
       "      <td>2240242</td>\n",
       "      <td>12.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>they sell sub sandwiches in 2 sizes  6 inch an...</td>\n",
       "      <td>1.949103</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>413367</td>\n",
       "      <td>6523590</td>\n",
       "      <td>13.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>these are the items to avoid if you want to ke...</td>\n",
       "      <td>-3.983741</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>413367</td>\n",
       "      <td>7476517</td>\n",
       "      <td>14.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>recipes for footlong black forest ham calories...</td>\n",
       "      <td>-3.978234</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>413367</td>\n",
       "      <td>3179622</td>\n",
       "      <td>15.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>these are the items to avoid if you want to ke...</td>\n",
       "      <td>-4.150008</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>413367</td>\n",
       "      <td>2240243</td>\n",
       "      <td>16.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>because of that  they are generally considered...</td>\n",
       "      <td>2.227004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>413367</td>\n",
       "      <td>2240241</td>\n",
       "      <td>17.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>they sell sub sandwiches in 2 sizes  6 inch an...</td>\n",
       "      <td>2.358280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>413367</td>\n",
       "      <td>5380063</td>\n",
       "      <td>18.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>they sell sub sandwiches in two sizes  6 inch ...</td>\n",
       "      <td>1.444870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>413367</td>\n",
       "      <td>5609822</td>\n",
       "      <td>19.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>double values for footlong  nutrition informat...</td>\n",
       "      <td>-2.271645</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>413367</td>\n",
       "      <td>1243415</td>\n",
       "      <td>20.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>subway s featured  5 footlong for april 2014 i...</td>\n",
       "      <td>-1.970864</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>413367</td>\n",
       "      <td>565939</td>\n",
       "      <td>21.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it s salami and pepperoni for a spicy italian ...</td>\n",
       "      <td>-1.362966</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>413367</td>\n",
       "      <td>4666277</td>\n",
       "      <td>22.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>there are 780 calories in a footlong veggie pa...</td>\n",
       "      <td>-3.940310</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>413367</td>\n",
       "      <td>7580619</td>\n",
       "      <td>23.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>some general guidelines  get a 6a3 sandwich  o...</td>\n",
       "      <td>1.596722</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>413367</td>\n",
       "      <td>336056</td>\n",
       "      <td>24.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>the root beer stand is located in sharonville ...</td>\n",
       "      <td>-3.063405</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>413367</td>\n",
       "      <td>4264206</td>\n",
       "      <td>25.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>i start working there tommorow and i have no i...</td>\n",
       "      <td>-1.234102</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>413367</td>\n",
       "      <td>4359506</td>\n",
       "      <td>26.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>subway   footlong flatbread spicy italian   pe...</td>\n",
       "      <td>-3.613807</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>413367</td>\n",
       "      <td>4359511</td>\n",
       "      <td>27.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>subway   footlong spicy italian flatbread   pe...</td>\n",
       "      <td>-3.808344</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>413367</td>\n",
       "      <td>7743147</td>\n",
       "      <td>28.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>the sub sandwiches were distributed on january...</td>\n",
       "      <td>-4.150645</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>413367</td>\n",
       "      <td>4936219</td>\n",
       "      <td>29.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>2  the featured decade dog  in 2014 when the c...</td>\n",
       "      <td>-3.991285</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>413367</td>\n",
       "      <td>1415675</td>\n",
       "      <td>30.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>the subway slogan is eat fresh  and it s true ...</td>\n",
       "      <td>-3.827467</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>413367</td>\n",
       "      <td>3895506</td>\n",
       "      <td>71.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>their means belonging to them   the homophon...</td>\n",
       "      <td>-2.803054</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>413367</td>\n",
       "      <td>3064351</td>\n",
       "      <td>72.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>from north to south  and coast to coast  tomat...</td>\n",
       "      <td>-4.486697</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>413367</td>\n",
       "      <td>5269951</td>\n",
       "      <td>73.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>saturn has official and unofficial moons on it...</td>\n",
       "      <td>-4.497292</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>413367</td>\n",
       "      <td>1415669</td>\n",
       "      <td>74.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>1 subway offers an array of baked chips  but h...</td>\n",
       "      <td>-4.473356</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>413367</td>\n",
       "      <td>4491</td>\n",
       "      <td>75.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>but go to the doc to get real help a s a p the...</td>\n",
       "      <td>-4.505943</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>413367</td>\n",
       "      <td>6438735</td>\n",
       "      <td>76.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>take some old sheets or canvas drop cloths  ve...</td>\n",
       "      <td>-4.535909</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>413367</td>\n",
       "      <td>2628115</td>\n",
       "      <td>77.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>wednesday  20 april 2016  you ve seen them on ...</td>\n",
       "      <td>-4.305362</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>413367</td>\n",
       "      <td>6265852</td>\n",
       "      <td>78.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>their means belonging to them   the homophon...</td>\n",
       "      <td>-3.190639</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>413367</td>\n",
       "      <td>8799733</td>\n",
       "      <td>79.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it is very difficult to remove salt once you h...</td>\n",
       "      <td>-4.524088</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>413367</td>\n",
       "      <td>7330773</td>\n",
       "      <td>80.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>cruising on cruise ships is a means of travel ...</td>\n",
       "      <td>-4.380171</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>413367</td>\n",
       "      <td>8711542</td>\n",
       "      <td>81.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it s a tradition  after all    a system devise...</td>\n",
       "      <td>-4.431039</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>413367</td>\n",
       "      <td>472806</td>\n",
       "      <td>82.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>porcupine description  the color of a porcupin...</td>\n",
       "      <td>-4.347814</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>413367</td>\n",
       "      <td>5584107</td>\n",
       "      <td>83.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>take some time off and kick some ass on facebo...</td>\n",
       "      <td>-4.467479</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>413367</td>\n",
       "      <td>3875694</td>\n",
       "      <td>84.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>unless you plan to eat them immediately  you s...</td>\n",
       "      <td>-4.527592</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>413367</td>\n",
       "      <td>7356726</td>\n",
       "      <td>85.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>grill some corn on the cob  take the corn cobs...</td>\n",
       "      <td>-4.576135</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>413367</td>\n",
       "      <td>1122261</td>\n",
       "      <td>86.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>prejudice is a preconceived notion about a gro...</td>\n",
       "      <td>-4.471276</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>413367</td>\n",
       "      <td>6799927</td>\n",
       "      <td>87.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>hippolyte taine  cats have been the protagonis...</td>\n",
       "      <td>-4.492202</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>413367</td>\n",
       "      <td>7475606</td>\n",
       "      <td>88.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>there are many alternative cryptocurrencies to...</td>\n",
       "      <td>-4.476259</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>413367</td>\n",
       "      <td>398864</td>\n",
       "      <td>89.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>their means belonging to them   the homophon...</td>\n",
       "      <td>-3.301845</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>413367</td>\n",
       "      <td>4528043</td>\n",
       "      <td>90.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>their means belonging to them   the homophone ...</td>\n",
       "      <td>-3.301845</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>413367</td>\n",
       "      <td>6413059</td>\n",
       "      <td>91.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>andyb64 new member  hi  i need to repair some ...</td>\n",
       "      <td>-4.426922</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>413367</td>\n",
       "      <td>704449</td>\n",
       "      <td>92.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>some swear by them  some say they are a waste ...</td>\n",
       "      <td>-4.416378</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>413367</td>\n",
       "      <td>4830084</td>\n",
       "      <td>93.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>their means belonging to them   the homophon...</td>\n",
       "      <td>-3.585776</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>413367</td>\n",
       "      <td>6157636</td>\n",
       "      <td>94.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>i planted some clematis last year  i need to p...</td>\n",
       "      <td>-4.474644</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>413367</td>\n",
       "      <td>6352733</td>\n",
       "      <td>95.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>a august 9  2011  women have highly variable e...</td>\n",
       "      <td>-4.505721</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>413367</td>\n",
       "      <td>8631041</td>\n",
       "      <td>96.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>magpie faq  birdwatch  received more queries a...</td>\n",
       "      <td>-4.475172</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>413367</td>\n",
       "      <td>3835076</td>\n",
       "      <td>97.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>then for the unclean person they shall take so...</td>\n",
       "      <td>-4.582019</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>413367</td>\n",
       "      <td>4662852</td>\n",
       "      <td>98.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>it depends on how you categorize them  for ins...</td>\n",
       "      <td>-4.293210</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>413367</td>\n",
       "      <td>4951657</td>\n",
       "      <td>99.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>a 100g of raw watermelon fruit contains    ...</td>\n",
       "      <td>-4.565885</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>413367</td>\n",
       "      <td>6515568</td>\n",
       "      <td>100.0</td>\n",
       "      <td>is it a footlong and them some</td>\n",
       "      <td>if you ve decided to start a small farm busine...</td>\n",
       "      <td>-4.531508</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id  passage_id  bm25_rank                           query  \\\n",
       "0     413367      670475        1.0  is it a footlong and them some   \n",
       "1     413367     4359509        2.0  is it a footlong and them some   \n",
       "2     413367     7279276        3.0  is it a footlong and them some   \n",
       "3     413367     5821389        4.0  is it a footlong and them some   \n",
       "4     413367     2340426        5.0  is it a footlong and them some   \n",
       "5     413367     6756670        6.0  is it a footlong and them some   \n",
       "6     413367     3179620        7.0  is it a footlong and them some   \n",
       "7     413367     2240246        8.0  is it a footlong and them some   \n",
       "8     413367     1243418        9.0  is it a footlong and them some   \n",
       "9     413367     2240245       10.0  is it a footlong and them some   \n",
       "10    413367     6756672       11.0  is it a footlong and them some   \n",
       "11    413367     2240242       12.0  is it a footlong and them some   \n",
       "12    413367     6523590       13.0  is it a footlong and them some   \n",
       "13    413367     7476517       14.0  is it a footlong and them some   \n",
       "14    413367     3179622       15.0  is it a footlong and them some   \n",
       "15    413367     2240243       16.0  is it a footlong and them some   \n",
       "16    413367     2240241       17.0  is it a footlong and them some   \n",
       "17    413367     5380063       18.0  is it a footlong and them some   \n",
       "18    413367     5609822       19.0  is it a footlong and them some   \n",
       "19    413367     1243415       20.0  is it a footlong and them some   \n",
       "20    413367      565939       21.0  is it a footlong and them some   \n",
       "21    413367     4666277       22.0  is it a footlong and them some   \n",
       "22    413367     7580619       23.0  is it a footlong and them some   \n",
       "23    413367      336056       24.0  is it a footlong and them some   \n",
       "24    413367     4264206       25.0  is it a footlong and them some   \n",
       "25    413367     4359506       26.0  is it a footlong and them some   \n",
       "26    413367     4359511       27.0  is it a footlong and them some   \n",
       "27    413367     7743147       28.0  is it a footlong and them some   \n",
       "28    413367     4936219       29.0  is it a footlong and them some   \n",
       "29    413367     1415675       30.0  is it a footlong and them some   \n",
       "..       ...         ...        ...                             ...   \n",
       "70    413367     3895506       71.0  is it a footlong and them some   \n",
       "71    413367     3064351       72.0  is it a footlong and them some   \n",
       "72    413367     5269951       73.0  is it a footlong and them some   \n",
       "73    413367     1415669       74.0  is it a footlong and them some   \n",
       "74    413367        4491       75.0  is it a footlong and them some   \n",
       "75    413367     6438735       76.0  is it a footlong and them some   \n",
       "76    413367     2628115       77.0  is it a footlong and them some   \n",
       "77    413367     6265852       78.0  is it a footlong and them some   \n",
       "78    413367     8799733       79.0  is it a footlong and them some   \n",
       "79    413367     7330773       80.0  is it a footlong and them some   \n",
       "80    413367     8711542       81.0  is it a footlong and them some   \n",
       "81    413367      472806       82.0  is it a footlong and them some   \n",
       "82    413367     5584107       83.0  is it a footlong and them some   \n",
       "83    413367     3875694       84.0  is it a footlong and them some   \n",
       "84    413367     7356726       85.0  is it a footlong and them some   \n",
       "85    413367     1122261       86.0  is it a footlong and them some   \n",
       "86    413367     6799927       87.0  is it a footlong and them some   \n",
       "87    413367     7475606       88.0  is it a footlong and them some   \n",
       "88    413367      398864       89.0  is it a footlong and them some   \n",
       "89    413367     4528043       90.0  is it a footlong and them some   \n",
       "90    413367     6413059       91.0  is it a footlong and them some   \n",
       "91    413367      704449       92.0  is it a footlong and them some   \n",
       "92    413367     4830084       93.0  is it a footlong and them some   \n",
       "93    413367     6157636       94.0  is it a footlong and them some   \n",
       "94    413367     6352733       95.0  is it a footlong and them some   \n",
       "95    413367     8631041       96.0  is it a footlong and them some   \n",
       "96    413367     3835076       97.0  is it a footlong and them some   \n",
       "97    413367     4662852       98.0  is it a footlong and them some   \n",
       "98    413367     4951657       99.0  is it a footlong and them some   \n",
       "99    413367     6515568      100.0  is it a footlong and them some   \n",
       "\n",
       "                                              passage  score_bert  bert_rank  \n",
       "0   cold cut combo   5 50  footlong  italian b m t...   -3.164047         29  \n",
       "1   cheese  amount on 6 inch sandwich  double valu...   -3.241947         33  \n",
       "2   footlong chicken   bacon ranch melt  with mayo...   -3.161703         28  \n",
       "3   calories in a footlong italian b m t  there ar...   -3.973064         53  \n",
       "4   cheese  amount on 6 inch sandwich  double valu...   -3.364845         35  \n",
       "5   footlong quarter pound coney  this sonic class...   -2.786904         21  \n",
       "6   unhealthiest options on the subway menu  1  fo...   -3.985879         56  \n",
       "7   it should be  10 99 a foot  but it depends on ...    1.892739          6  \n",
       "8   news  subway april 2014 featured  5 footlong  ...   -2.421246         19  \n",
       "9   how much is a 3ft subway sandwich  it should b...   -2.166980         16  \n",
       "10  now you can get approximately twice the sodium...   -3.688279         44  \n",
       "11  they sell sub sandwiches in 2 sizes  6 inch an...    1.949103          4  \n",
       "12  these are the items to avoid if you want to ke...   -3.983741         55  \n",
       "13  recipes for footlong black forest ham calories...   -3.978234         54  \n",
       "14  these are the items to avoid if you want to ke...   -4.150008         59  \n",
       "15  because of that  they are generally considered...    2.227004          2  \n",
       "16  they sell sub sandwiches in 2 sizes  6 inch an...    2.358280          1  \n",
       "17  they sell sub sandwiches in two sizes  6 inch ...    1.444870          9  \n",
       "18  double values for footlong  nutrition informat...   -2.271645         17  \n",
       "19  subway s featured  5 footlong for april 2014 i...   -1.970864         15  \n",
       "20  it s salami and pepperoni for a spicy italian ...   -1.362966         13  \n",
       "21  there are 780 calories in a footlong veggie pa...   -3.940310         52  \n",
       "22  some general guidelines  get a 6a3 sandwich  o...    1.596722          8  \n",
       "23  the root beer stand is located in sharonville ...   -3.063405         25  \n",
       "24  i start working there tommorow and i have no i...   -1.234102         12  \n",
       "25  subway   footlong flatbread spicy italian   pe...   -3.613807         41  \n",
       "26  subway   footlong spicy italian flatbread   pe...   -3.808344         48  \n",
       "27  the sub sandwiches were distributed on january...   -4.150645         60  \n",
       "28  2  the featured decade dog  in 2014 when the c...   -3.991285         57  \n",
       "29  the subway slogan is eat fresh  and it s true ...   -3.827467         50  \n",
       "..                                                ...         ...        ...  \n",
       "70    their means belonging to them   the homophon...   -2.803054         22  \n",
       "71  from north to south  and coast to coast  tomat...   -4.486697         86  \n",
       "72  saturn has official and unofficial moons on it...   -4.497292         88  \n",
       "73  1 subway offers an array of baked chips  but h...   -4.473356         82  \n",
       "74  but go to the doc to get real help a s a p the...   -4.505943         90  \n",
       "75  take some old sheets or canvas drop cloths  ve...   -4.535909         95  \n",
       "76  wednesday  20 april 2016  you ve seen them on ...   -4.305362         68  \n",
       "77    their means belonging to them   the homophon...   -3.190639         31  \n",
       "78  it is very difficult to remove salt once you h...   -4.524088         92  \n",
       "79  cruising on cruise ships is a means of travel ...   -4.380171         72  \n",
       "80  it s a tradition  after all    a system devise...   -4.431039         76  \n",
       "81  porcupine description  the color of a porcupin...   -4.347814         69  \n",
       "82  take some time off and kick some ass on facebo...   -4.467479         80  \n",
       "83  unless you plan to eat them immediately  you s...   -4.527592         93  \n",
       "84  grill some corn on the cob  take the corn cobs...   -4.576135         97  \n",
       "85  prejudice is a preconceived notion about a gro...   -4.471276         81  \n",
       "86  hippolyte taine  cats have been the protagonis...   -4.492202         87  \n",
       "87  there are many alternative cryptocurrencies to...   -4.476259         85  \n",
       "88    their means belonging to them   the homophon...   -3.301845         34  \n",
       "89  their means belonging to them   the homophone ...   -3.301845         34  \n",
       "90  andyb64 new member  hi  i need to repair some ...   -4.426922         75  \n",
       "91  some swear by them  some say they are a waste ...   -4.416378         74  \n",
       "92    their means belonging to them   the homophon...   -3.585776         38  \n",
       "93  i planted some clematis last year  i need to p...   -4.474644         83  \n",
       "94  a august 9  2011  women have highly variable e...   -4.505721         89  \n",
       "95  magpie faq  birdwatch  received more queries a...   -4.475172         84  \n",
       "96  then for the unclean person they shall take so...   -4.582019         98  \n",
       "97  it depends on how you categorize them  for ins...   -4.293210         67  \n",
       "98     a 100g of raw watermelon fruit contains    ...   -4.565885         96  \n",
       "99  if you ve decided to start a small farm busine...   -4.531508         94  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
