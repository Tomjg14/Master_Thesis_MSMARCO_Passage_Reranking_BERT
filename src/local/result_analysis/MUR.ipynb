{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will compute the MUR between the BM25 en BERT ranking for the top 100 on the development set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm.auto import tqdm \n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "# BM25 top 100 ranking\n",
    "bm25_top100_filename = 'run_development_top100.tsv'\n",
    "\n",
    "# BERT top 100 ranking\n",
    "bert_top100_filename = 'bert_thesis_dataset_top100.tsv'\n",
    "\n",
    "# Experiment query ids\n",
    "thesis_query_subset = 'experiment_query_subset.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_df = pd.read_csv(data_dir + bm25_top100_filename,delimiter='\\t',encoding='utf-8',header=None)\n",
    "bm25_df.columns = ['query_id', 'passage_id', 'bm25_rank']\n",
    "\n",
    "bert_df = pd.read_csv(data_dir + bert_top100_filename,delimiter='\\t',encoding='utf-8',header=None)\n",
    "bert_df.columns = ['query_id', 'passage_id', 'bm25_rank', 'query', 'passage', 'bert_score', 'bert_rank']\n",
    "\n",
    "query_subset = pd.read_csv(data_dir + thesis_query_subset,delimiter='\\t',encoding='utf-8',header=None)\n",
    "query_subset.columns = ['query_id', 'query']\n",
    "\n",
    "models_dict = {\"bm25\": bm25_df, \"bert\": bert_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_ids(dataframe):\n",
    "    return list(np.unique(dataframe['query_id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_ranking(dataframe,rank_column,n):\n",
    "    top_n_ranking = dataframe[dataframe[rank_column] <= n].sort_values(by=[rank_column])\n",
    "    return top_n_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mur(query_id,i):\n",
    "    matches = 0\n",
    "    bm25_top_n_passages = bert_df[(bert_df['query_id'] == query_id) & (bert_df['bm25_rank'] <= i)].sort_values(by=['bm25_rank'])['passage_id'].values.tolist()\n",
    "    bert_top_n_passages = bert_df[(bert_df['query_id'] == query_id) & (bert_df['bert_rank'] <= i)].sort_values(by=['bert_rank'])['passage_id'].values.tolist()\n",
    "    for index, passage_id in enumerate(bm25_top_n_passages):\n",
    "        if bert_top_n_passages[index] == passage_id:\n",
    "            matches += 1\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_murs = {}\n",
    "for i in range(1,11):\n",
    "    summed_mur = 0\n",
    "    for query_id in query_ids:\n",
    "        mur = compute_mur(query_id,i)\n",
    "        summed_mur += mur\n",
    "    avg_mur = summed_mur/len(query_ids)\n",
    "    avg_murs[i] = round(avg_mur,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.33,\n",
       " 2: 0.53,\n",
       " 3: 0.58,\n",
       " 4: 0.65,\n",
       " 5: 0.72,\n",
       " 6: 0.81,\n",
       " 7: 0.86,\n",
       " 8: 0.88,\n",
       " 9: 0.88,\n",
       " 10: 0.91}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_murs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
