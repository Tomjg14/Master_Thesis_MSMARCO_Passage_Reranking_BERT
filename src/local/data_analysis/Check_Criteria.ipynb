{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps to analyse all assessed queries in order to check if they meet the following three criteria:\n",
    "1. 3 or more assessors assessed the query\n",
    "2. the ms marco relevant passage is assessed relevant as well\n",
    "3. the ms marco relevant passage is not the only relevant assessed passage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "firebase_data = 'data/data.json'\n",
    "query_subset_filename = 'data/queries.dev.small.tsv'\n",
    "qrels_filename = 'data/qrels.dev.small.tsv'\n",
    "assessor_info = 'data/assessor_info.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(firebase_data, 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "query_ids = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_subset = pd.read_csv(query_subset_filename,delimiter='\\t',encoding='utf-8', header=None)\n",
    "query_subset.columns = ['query_id', 'query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = pd.read_csv(qrels_filename,delimiter='\\t',encoding='utf-8',header=None)\n",
    "qrels_df.columns = ['query_id','label1','passage_id','label2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessor_df = pd.read_csv(assessor_info,delimiter='\\t',encoding='utf-8',header=None)\n",
    "assessor_df.columns = [\"user_id\",\"email\",\"consent\",\"contact\",\"english\",\"progress\",\"assessed_queries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrames per Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(nr_assessors):\n",
    "    labels = [\"query_id\",\"passageid\",\"msmarco\"]\n",
    "    for i in range(nr_assessors):\n",
    "        labels = labels + ['user%s_id'%(i+1),'user%s_label'%(i+1)]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_data = {}\n",
    "label_data = {}\n",
    "assessor_data = {}\n",
    "for query_id in query_ids:\n",
    "    query_data_lists = []\n",
    "    query_data = data[query_id]\n",
    "    nr_assessors = 0\n",
    "    for i, passage_id in enumerate(query_data.keys()):\n",
    "        dataFrameRow2be = [query_id, passage_id] + query_data[passage_id]\n",
    "        query_data_lists.append(dataFrameRow2be)\n",
    "        if i == 0:\n",
    "            nr_assessors = int((len(query_data[passage_id])-1)/2)\n",
    "    dataframe_data[query_id] = query_data_lists\n",
    "    label_data[query_id] = create_labels(nr_assessors)\n",
    "    assessor_data[query_id] = nr_assessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "for query_id in query_ids:\n",
    "    df = pd.DataFrame(dataframe_data[query_id],columns=label_data[query_id])\n",
    "    dataframes[query_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993153\n",
      "973362\n",
      "92542\n",
      "637459\n",
      "426442\n",
      "785176\n",
      "1101714\n",
      "758519\n",
      "904389\n",
      "202306\n",
      "1083852\n",
      "736125\n",
      "689885\n",
      "971653\n",
      "1097449\n",
      "38946\n",
      "1096257\n",
      "825147\n",
      "257885\n",
      "988142\n",
      "1045826\n",
      "1077356\n",
      "nr of queries with missing data: 22\n"
     ]
    }
   ],
   "source": [
    "queries_with_missing_data = []\n",
    "counter = 0\n",
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    if 'no_input' in df.values:\n",
    "        counter += 1\n",
    "        print(query_id)\n",
    "        queries_with_missing_data.append(query_id)\n",
    "print(\"nr of queries with missing data: %s\"%(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993153\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "19\n",
      "user3_label\n",
      "1\n",
      "user4_label\n",
      "0\n",
      "user5_label\n",
      "0\n",
      "user6_label\n",
      "0\n",
      "user7_label\n",
      "0\n",
      "\n",
      "\n",
      "973362\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "\n",
      "\n",
      "92542\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "\n",
      "\n",
      "637459\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "426442\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "3\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "785176\n",
      "user1_label\n",
      "2\n",
      "\n",
      "\n",
      "1101714\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "758519\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "904389\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "\n",
      "\n",
      "202306\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "1083852\n",
      "user1_label\n",
      "2\n",
      "\n",
      "\n",
      "736125\n",
      "user1_label\n",
      "2\n",
      "\n",
      "\n",
      "689885\n",
      "user1_label\n",
      "1\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "971653\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "1097449\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "user4_label\n",
      "1\n",
      "user5_label\n",
      "0\n",
      "user6_label\n",
      "0\n",
      "user7_label\n",
      "0\n",
      "\n",
      "\n",
      "38946\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "1096257\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "825147\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "user4_label\n",
      "0\n",
      "user5_label\n",
      "0\n",
      "\n",
      "\n",
      "257885\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "988142\n",
      "user1_label\n",
      "9\n",
      "\n",
      "\n",
      "1045826\n",
      "user1_label\n",
      "1\n",
      "\n",
      "\n",
      "1077356\n",
      "user1_label\n",
      "1\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_id in queries_with_missing_data:\n",
    "    print(query_id)\n",
    "    df = dataframes[query_id]\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    user_id_columns = [\"user%s_label\"%(i+1) for i in range(nr_assessors)]\n",
    "    for user_id_column in user_id_columns:\n",
    "        print(user_id_column)\n",
    "        print(len(df[df[user_id_column].isin([\"no_input\"])]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the times it is just one data entry. Except for query 993153 for which user 2 only entered one label. We could either remove this query entirely from the dataset or we could just leave out the input from user 2 as there are 6 other assessors for this query. I will do the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframes['993153']['user2_label']\n",
    "del dataframes['993153']['user2_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessor_data['993153'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_assessors = assessor_data['993153']\n",
    "user_column_names = []\n",
    "for i in range(nr_assessors):\n",
    "    user_column_names = user_column_names + [\"user%s_id\"%(i+1), \"user%s_label\"%(i+1)]\n",
    "dataframes['993153'].columns = ['query_id','passageid','msmarco'] + user_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check how many queries do not have at least 3 assessors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "print(len(query_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_then_3 = []\n",
    "for query_id in query_ids:\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if not nr_assessors >= 3:\n",
    "        less_then_3.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "print(len(less_then_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we continue with the remaining queries to see for how many of these the assessors agree with the MS MARCO relevant passage. We take a binary threshold of 3 because this causes the more irrelevant passages than taking a threshold of 2. Which would result in more disagreement with the original relevant passage. Moreover, for the graded case we look for the cases where the MS MARCO relevant passage is assessed with a grade 1 (totally irrelevant). We also consider the cases where the MS MARCO relevant passage is not located in the top 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListUserLabelColumns(nr_assessors):\n",
    "    label_columns = []\n",
    "    for i in range(nr_assessors):\n",
    "        label_columns.append(\"user%s_label\"%(i+1))\n",
    "    return label_columns\n",
    "\n",
    "def makeBinary(labels):\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if not label == \"no_input\":\n",
    "            if int(label) < binary_threshold:\n",
    "                binary_labels.append(0)\n",
    "            else:\n",
    "                binary_labels.append(1)\n",
    "        else:\n",
    "            binary_labels.append(label)\n",
    "    return binary_labels\n",
    "\n",
    "def getAgreementLabel(msmarco_label,labels):\n",
    "    if \"no_input\" in labels:\n",
    "        labels.remove('no_input')\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)\n",
    "    else:\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)\n",
    "        \n",
    "def usersDoAgree(labels):\n",
    "    if len(set(labels)) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def performMajorityVote(msmarco_label,labels):\n",
    "    count_votes = Counter(labels)\n",
    "    majority_label = msmarco_label\n",
    "    if (len(labels) % 2) == 0:\n",
    "        vote_threshold = int(len(labels)/2)\n",
    "        for label,votes in count_votes.items():\n",
    "            if votes > vote_threshold:\n",
    "                majority_label = label\n",
    "    else:\n",
    "        vote_threshold = int(np.ceil(len(labels)/2))\n",
    "        for label, votes in count_votes.items():\n",
    "            if votes >= vote_threshold:\n",
    "                majority_label = label\n",
    "    return majority_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427323\n",
      "321951\n",
      "838453\n",
      "993987\n",
      "866251\n",
      "540906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomjg\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# < 3 is irrelevant >= 3 is relevant\n",
    "binary_threshold = 3\n",
    "counter_no_relevant_in_top_20 = 0\n",
    "counter_disagreement = 0\n",
    "\n",
    "no_top20_ms_marco = []\n",
    "no_agreement = []\n",
    "\n",
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    agreement_labels = []\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        relevant_row = df.loc[df['msmarco'] == 'relevant']\n",
    "        if not len(relevant_row) == 0:\n",
    "            relevant_row['msmarco_binary'] = relevant_row['msmarco'].apply(lambda x: 0 if (x == 'irrelevant') else 1)\n",
    "            user_labels = relevant_row[getListUserLabelColumns(nr_assessors)].values[0]\n",
    "            binary_labels = makeBinary(user_labels)\n",
    "            agreement_label = getAgreementLabel(relevant_row['msmarco_binary'],binary_labels)\n",
    "            if agreement_label == 0:\n",
    "                print(query_id)\n",
    "                counter_disagreement += 1\n",
    "                no_agreement.append(query_id)\n",
    "        else:\n",
    "            counter_no_relevant_in_top_20 += 1\n",
    "            no_top20_ms_marco.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(counter_no_relevant_in_top_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(counter_disagreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2int(labels):\n",
    "    integer_labels = []\n",
    "    for label in labels:\n",
    "        if not label == \"no_input\":\n",
    "            integer_labels.append(int(label))\n",
    "    return integer_labels\n",
    "\n",
    "def getAgreementLabel(labels):\n",
    "    return int(np.ceil(np.median(labels)))\n",
    "\n",
    "def toNum(label):\n",
    "    if label == \"irrelevant\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427323\n",
      "993987\n",
      "540906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomjg\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\tomjg\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "counter_no_relevant_in_top_20_graded = 0\n",
    "counter_disagreement_graded = 0\n",
    "\n",
    "no_agreement_graded = []\n",
    "no_top20_ms_marco_graded = []\n",
    "\n",
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        relevant_row = df.loc[df['msmarco'] == 'relevant']\n",
    "        if not len(relevant_row) == 0:\n",
    "            assessor_labels = relevant_row.iloc[:,4::2].values[0]\n",
    "            integer_labels = str2int(assessor_labels)\n",
    "            agreement_label = getAgreementLabel(integer_labels)\n",
    "            relevant_row['agreement_label'] = agreement_label\n",
    "            relevant_row['msmarco'] = toNum(relevant_row['msmarco'].values)\n",
    "            [msmarco_label, agreement_label] = relevant_row[['msmarco','agreement_label']].values[0]\n",
    "            if agreement_label == 1:\n",
    "                print(query_id)\n",
    "                counter_disagreement_graded += 1\n",
    "                no_agreement_graded.append(query_id)\n",
    "        else:\n",
    "            counter_no_relevant_in_top_20_graded += 1\n",
    "            no_top20_ms_marco_graded.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(counter_no_relevant_in_top_20_graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(counter_disagreement_graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_agreement_total = []\n",
    "for query_id in no_agreement:\n",
    "    if not query_id in no_agreement_total:\n",
    "        no_agreement_total.append(query_id)\n",
    "        \n",
    "for query_id in no_agreement_graded:\n",
    "    if not query_id in no_agreement_total:\n",
    "        no_agreement_total.append(query_id)\n",
    "        \n",
    "for query_id in no_top20_ms_marco:\n",
    "    if not query_id in no_agreement_total:\n",
    "        no_agreement_total.append(query_id)\n",
    "        \n",
    "for query_id in no_top20_ms_marco_graded:\n",
    "    if not query_id in no_agreement_total:\n",
    "        no_agreement_total.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(no_agreement_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we continue with the remaining queries to see if it is not the case that the MS MARCO relevant passage is the only relevant one. Again we do this for both the threshold=3 and graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Treshold=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    df['msmarco_binary'] = df['msmarco'].apply(lambda x: 0 if (x == 'irrelevant') else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBinary(labels):\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if not label == \"no_input\":\n",
    "            if int(label) < binary_threshold:\n",
    "                binary_labels.append(0)\n",
    "            else:\n",
    "                binary_labels.append(1)\n",
    "        else:\n",
    "            binary_labels.append(label)\n",
    "    return binary_labels\n",
    "\n",
    "def getListUserLabelColumns(nr_assessors):\n",
    "    label_columns = []\n",
    "    for i in range(nr_assessors):\n",
    "        label_columns.append(\"user%s_label\"%(i+1))\n",
    "    return label_columns\n",
    "\n",
    "def getAgreementLabel(msmarco_label,labels):\n",
    "    if \"no_input\" in labels:\n",
    "        labels.remove('no_input')\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)\n",
    "    else:\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)\n",
    "        \n",
    "def usersDoAgree(labels):\n",
    "    if len(set(labels)) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def performMajorityVote(msmarco_label,labels):\n",
    "    count_votes = Counter(labels)\n",
    "    majority_label = msmarco_label\n",
    "    if (len(labels) % 2) == 0:\n",
    "        vote_threshold = int(len(labels)/2)\n",
    "        for label,votes in count_votes.items():\n",
    "            if votes > vote_threshold:\n",
    "                majority_label = label\n",
    "    else:\n",
    "        vote_threshold = int(np.ceil(len(labels)/2))\n",
    "        for label, votes in count_votes.items():\n",
    "            if votes >= vote_threshold:\n",
    "                majority_label = label\n",
    "    return majority_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489257\n",
      "335710\n"
     ]
    }
   ],
   "source": [
    "# < 3 is irrelevant >= 3 is relevant\n",
    "binary_threshold = 3\n",
    "\n",
    "count_cases_where_only_ms_relevant = 0\n",
    "ms_only_relevant_binary = []\n",
    "\n",
    "\n",
    "for query_id in query_ids:\n",
    "    if not query_id in less_then_3:\n",
    "        if not query_id in no_agreement_total:\n",
    "            df = dataframes[query_id]\n",
    "            agreement_labels = []\n",
    "            nr_assessors = assessor_data[query_id]\n",
    "            if nr_assessors >= 3:\n",
    "                for index, row in df.iterrows():\n",
    "                    user_labels = row[getListUserLabelColumns(nr_assessors)].values\n",
    "                    binary_labels = makeBinary(user_labels)\n",
    "                    agreement_label = getAgreementLabel(row['msmarco_binary'],binary_labels)\n",
    "                    agreement_labels.append(agreement_label)\n",
    "                df['agreement_label'] = agreement_labels\n",
    "                if (len(df[(df['msmarco_binary'] == 1) & (df['agreement_label'] == 1)]) == 1):\n",
    "                    if(sum(df[df['msmarco_binary'] == 0]['agreement_label'].values.tolist()) == 0):\n",
    "                        count_cases_where_only_ms_relevant += 1\n",
    "                        print(query_id)\n",
    "                        ms_only_relevant_binary.append(query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListUserLabelColumns(nr_assessors):\n",
    "    label_columns = []\n",
    "    for i in range(nr_assessors):\n",
    "        label_columns.append(\"user%s_label\"%(i+1))\n",
    "    return label_columns\n",
    "\n",
    "def str2int(labels):\n",
    "    integer_labels = []\n",
    "    for label in labels:\n",
    "        if not label == \"no_input\":\n",
    "            integer_labels.append(int(label))\n",
    "    return integer_labels\n",
    "\n",
    "def getAgreementLabel(labels):\n",
    "    return int(np.ceil(np.median(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cases_where_only_ms_relevant = 0\n",
    "ms_only_relevant_graded = []\n",
    "\n",
    "for query_id in query_ids:\n",
    "    if not query_id in less_then_3:\n",
    "        if not query_id in no_agreement_total:\n",
    "            df = dataframes[query_id]\n",
    "            agreement_labels = []\n",
    "            nr_assessors = assessor_data[query_id]\n",
    "            if nr_assessors >= 3:\n",
    "                for index, row in df.iterrows():\n",
    "                    user_labels = row[getListUserLabelColumns(nr_assessors)].values\n",
    "                    integer_labels = str2int(user_labels)\n",
    "                    agreement_label = getAgreementLabel(integer_labels)\n",
    "                    agreement_labels.append(agreement_label)\n",
    "                df['agreement_label'] = agreement_labels\n",
    "                unique_labels = set(df[df['msmarco'] == 'irrelevant']['agreement_label'].values.tolist())\n",
    "                if len(unique_labels) == 1 and unique_labels[0] == 1:\n",
    "                    count_cases_where_only_ms_relevant += 1\n",
    "                    ms_only_relevant_graded.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_only_relevant_total = []\n",
    "\n",
    "for query_id in ms_only_relevant_binary:\n",
    "    if not query_id in ms_only_relevant_total:\n",
    "        ms_only_relevant_total.append(query_id)\n",
    "        \n",
    "for query_id in ms_only_relevant_graded:\n",
    "    if not query_id in ms_only_relevant_total:\n",
    "        ms_only_relevant_total.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['489257', '335710']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_only_relevant_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Experiment Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_queries = []\n",
    "for query_id in query_ids:\n",
    "    if not query_id in less_then_3:\n",
    "        if not query_id in no_agreement_total:\n",
    "            if not query_id in ms_only_relevant_total:\n",
    "                experiment_queries.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(experiment_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/experiment_queries.txt\",\"w\") as outfile:\n",
    "    for query_id in experiment_queries:\n",
    "        line = \"%s\\n\"%(query_id)\n",
    "        outfile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
