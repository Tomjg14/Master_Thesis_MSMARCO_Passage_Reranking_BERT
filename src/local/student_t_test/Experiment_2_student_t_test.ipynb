{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should help to compute the Student T test for different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"bm25\"\n",
    "model2 = \"bert\"\n",
    "\n",
    "dataset = \"threshold=3\"\n",
    "metric = \"map\"\n",
    "cutoff = 10\n",
    "\n",
    "file1 = \"output/%s/%s_scores_%s_%s_N%s.txt\"%(metric,metric,model1,dataset,cutoff)\n",
    "file2 = \"output/%s/%s_scores_%s_%s_N%s.txt\"%(metric,metric,model2,dataset,cutoff)\n",
    "\n",
    "output_file = \"output/student_t_test_output/student_t_test_results_experiment2_%s_%s_vs_%s_%s_N%s.txt\"%(dataset,model1,model2,metric,cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "with open (file1,'r') as infile:\n",
    "    for line in infile:\n",
    "        data1.append(float(line.rstrip().split()[1]))\n",
    "        \n",
    "data2 = []\n",
    "with open (file2,'r') as infile:\n",
    "    for line in infile:\n",
    "        data2.append(float(line.rstrip().split()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test for dependent samples\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the t-test for two dependent samples\n",
    "def dependent_ttest(data1, data2, alpha):\n",
    "    # calculate means\n",
    "    mean1, mean2 = mean(data1), mean(data2)\n",
    "    \n",
    "    # number of paired samples\n",
    "    n = len(data1)\n",
    "    \n",
    "    # sum squared difference between observations\n",
    "    d1 = sum([(data1[i]-data2[i])**2 for i in range(n)])\n",
    "    \n",
    "    # sum difference between observations\n",
    "    d2 = sum([data1[i]-data2[i] for i in range(n)])\n",
    "    \n",
    "    # standard deviation of the difference between means\n",
    "    sd = sqrt((d1 - (d2**2 / n)) / (n - 1))\n",
    "    \n",
    "    # standard error of the difference between the means\n",
    "    sed = sd / sqrt(n)\n",
    "    \n",
    "    # calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    \n",
    "    # degrees of freedom\n",
    "    df = n - 1\n",
    "    \n",
    "    # calculate the critical value\n",
    "    cv = t.ppf(1.0 - alpha, df)\n",
    "    \n",
    "    # calculate the p-value\n",
    "    p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "    \n",
    "    # return everything\n",
    "    return t_stat, df, cv, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the t test\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = dependent_ttest(data1, data2, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.757, df=42, cv=1.682, p=0.4534528482\n"
     ]
    }
   ],
   "source": [
    "print('t=%.3f, df=%d, cv=%.3f, p=%.10f' % (t_stat, df, cv, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept null hypothesis that the means are equal.\n",
      "Accept null hypothesis that the means are equal.\n"
     ]
    }
   ],
   "source": [
    "if abs(t_stat) <= cv:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file,'w') as outfile:\n",
    "    outfile.write(\"model1: %s\\n\"%(model1))\n",
    "    outfile.write(\"model2: %s\\n\"%(model2))\n",
    "    outfile.write(\"dataset: %s\\n\"%(dataset))\n",
    "    outfile.write(\"metric: %s@%s\\n\"%(metric,cutoff))\n",
    "    outfile.write(\"alpha: %s\\n\\n\"%(alpha))\n",
    "    outfile.write('t=%.3f, df=%d, cv=%.3f, p=%.10f\\n\\n' % (t_stat, df, cv, p))\n",
    "    outfile.write(\"interpret via critical value:\\n\")\n",
    "    outfile.write(\"t <= cv\\n\")\n",
    "    if abs(t_stat) <= cv:\n",
    "        outfile.write('Accept null hypothesis that the means are equal.\\n\\n')\n",
    "    else:\n",
    "        outfile.write('Reject the null hypothesis that the means are equal.\\n\\n')\n",
    "    outfile.write(\"interpret via p-value:\\n\")\n",
    "    outfile.write(\"p > alpha\\n\")\n",
    "    if p > alpha:\n",
    "        outfile.write('Accept null hypothesis that the means are equal.\\n')\n",
    "    else:\n",
    "        outfile.write('Reject the null hypothesis that the means are equal.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
