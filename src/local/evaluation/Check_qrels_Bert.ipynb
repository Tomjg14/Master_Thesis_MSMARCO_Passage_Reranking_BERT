{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_rank_df = pd.read_csv(data_dir + 'bert_thesis_dataset_top100.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "bert_rank_df.columns = ['query_id', 'passage_id','bm25_rank','query','passage','bert_score', 'bert_rank']\n",
    "og_qrels_df = pd.read_csv(data_dir + 'qrels.dev.small.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "og_qrels_df.columns = ['query_id','label1','passage_id','label2']\n",
    "queries_df = pd.read_csv(data_dir + 'queries.dev.small.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "queries_df.columns = ['query_id','query']\n",
    "new_qrels_df = pd.read_csv(data_dir + 'thesis_qrels.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "new_qrels_df.columns = ['query_id','label1','passage_id','label2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_qrels_list = []\n",
    "for index, row in og_qrels_df.iterrows():\n",
    "    [query_id,passage_id] = row.values[::2]\n",
    "    og_qrels_list.append((query_id,passage_id))\n",
    "\n",
    "new_qrels_list = []\n",
    "for index, row in new_qrels_df.iterrows():\n",
    "    [query_id,passage_id] = row.values[::2]\n",
    "    new_qrels_list.append((query_id,passage_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_relevance_column_list = []\n",
    "new_relevance_column_list = []\n",
    "for index, row in bert_rank_df.iterrows():\n",
    "    [query_id,passage_id] = row.values[:2]\n",
    "    if (query_id,passage_id) in og_qrels_list:\n",
    "        og_relevance_column_list.append(1)\n",
    "    else:\n",
    "        og_relevance_column_list.append(0)\n",
    "    if (query_id,passage_id) in new_qrels_list:\n",
    "        new_relevance_column_list.append(1)\n",
    "    else:\n",
    "        new_relevance_column_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_rank_df['og_rel'] = og_relevance_column_list\n",
    "bert_rank_df['new_rel'] = new_relevance_column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_rank_df[(bert_rank_df['bert_rank'] == 1) & (bert_rank_df['og_rel'] == 0) & (bert_rank_df['new_rel'] == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 cases where the original msmarco relevant passage is not ranked 1 by BERT but a newly labeled relevant passage is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_rank_df[(bert_rank_df['bert_rank'] == 1) & (bert_rank_df['og_rel'] == 0) & (bert_rank_df['new_rel'] == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 cases where both the original msmarco relevant passage and the newly ranked relevant passage are not ranked 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_rank_df[(bert_rank_df['bert_rank'] == 1) & (bert_rank_df['og_rel'] == 1) & (bert_rank_df['new_rel'] == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 cases where both the original msmarco relevant passage and newly ranked relevant passage are ranked 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_rank_df[(bert_rank_df['bert_rank'] == 1) & (bert_rank_df['og_rel'] == 1) & (bert_rank_df['new_rel'] == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 cases where the msmarco relevant passage is not ranked relevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
