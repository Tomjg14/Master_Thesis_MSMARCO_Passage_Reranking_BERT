{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to create a relevance label dataset where we use binary labels (either relevant or irrelevant). The threshold to determine if a label should be relevant or irrelevant is 2. If subjects agree on a label less than 2 it is irrelevant, otherwise the label is relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "query_ids = list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes per Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(nr_assessors):\n",
    "    labels = [\"query_id\",\"passageid\",\"msmarco\"]\n",
    "    for i in range(nr_assessors):\n",
    "        labels = labels + ['user%s_id'%(i+1),'user%s_label'%(i+1)]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_data = {}\n",
    "label_data = {}\n",
    "assessor_data = {}\n",
    "for query_id in query_ids:\n",
    "    query_data_lists = []\n",
    "    query_data = data[query_id]\n",
    "    nr_assessors = 0\n",
    "    for i, passage_id in enumerate(query_data.keys()):\n",
    "        dataFrameRow2be = [query_id, passage_id] + query_data[passage_id]\n",
    "        query_data_lists.append(dataFrameRow2be)\n",
    "        if i == 0:\n",
    "            nr_assessors = int((len(query_data[passage_id])-1)/2)\n",
    "    dataframe_data[query_id] = query_data_lists\n",
    "    label_data[query_id] = create_labels(nr_assessors)\n",
    "    assessor_data[query_id] = nr_assessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "for query_id in query_ids:\n",
    "    df = pd.DataFrame(dataframe_data[query_id],columns=label_data[query_id])\n",
    "    dataframes[query_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Binary MSMARCO Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    df['msmarco_binary'] = df['msmarco'].apply(lambda x: 0 if (x == 'irrelevant') else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes an assessors forgot to provide input, which means that the dataset includes \"no_input\". This is missing data and often we can fix this by considering the input of the remaining assessors. If the remaining assessors agree, I can still provide the agreed relevance label. If there is no agreement between the remaining assessors, I simply take the relevance label that MSMARCO provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825147\n",
      "1097449\n",
      "758519\n",
      "689885\n",
      "426442\n",
      "904389\n",
      "202306\n",
      "1077356\n",
      "1096257\n",
      "92542\n",
      "993153\n",
      "nr of queries with missing data: 11\n"
     ]
    }
   ],
   "source": [
    "queries_with_missing_data = []\n",
    "counter = 0\n",
    "for query_id in query_ids:\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        df = dataframes[query_id]\n",
    "        if 'no_input' in df.values:\n",
    "            counter += 1\n",
    "            print(query_id)\n",
    "            queries_with_missing_data.append(query_id)\n",
    "print(\"nr of queries with missing data: %s\"%(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825147\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "user4_label\n",
      "0\n",
      "user5_label\n",
      "0\n",
      "\n",
      "\n",
      "1097449\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "user4_label\n",
      "1\n",
      "user5_label\n",
      "0\n",
      "user6_label\n",
      "0\n",
      "user7_label\n",
      "0\n",
      "\n",
      "\n",
      "758519\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "689885\n",
      "user1_label\n",
      "1\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "426442\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "3\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "904389\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "\n",
      "\n",
      "202306\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "1077356\n",
      "user1_label\n",
      "1\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "1096257\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "1\n",
      "user3_label\n",
      "0\n",
      "\n",
      "\n",
      "92542\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "0\n",
      "user3_label\n",
      "1\n",
      "\n",
      "\n",
      "993153\n",
      "user1_label\n",
      "0\n",
      "user2_label\n",
      "19\n",
      "user3_label\n",
      "1\n",
      "user4_label\n",
      "0\n",
      "user5_label\n",
      "0\n",
      "user6_label\n",
      "0\n",
      "user7_label\n",
      "0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_id in queries_with_missing_data:\n",
    "    print(query_id)\n",
    "    df = dataframes[query_id]\n",
    "    column_labels = list(df.columns)\n",
    "    for i in range(7):\n",
    "        column = 'user%s_label'%(i+1)\n",
    "        if column in column_labels:\n",
    "            print(column)\n",
    "            print(len(df[df[column].isin([\"no_input\"])]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most queries have just one 'no_input' entry, except for query 993153 which has 19 entries. So we need to remove this query from the data and find a way to deal with the remaining queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids.remove('993153')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Binary Agreement Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < 2 is irrelevant >= 2 is relevant\n",
    "binary_threshold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListUserLabelColumns(nr_assessors):\n",
    "    label_columns = []\n",
    "    for i in range(nr_assessors):\n",
    "        label_columns.append(\"user%s_label\"%(i+1))\n",
    "    return label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBinary(labels):\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if not label == \"no_input\":\n",
    "            if int(label) < binary_threshold:\n",
    "                binary_labels.append(0)\n",
    "            else:\n",
    "                binary_labels.append(1)\n",
    "        else:\n",
    "            binary_labels.append(label)\n",
    "    return binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgreementLabel(msmarco_label,labels):\n",
    "    if \"no_input\" in labels:\n",
    "        labels.remove('no_input')\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)\n",
    "    else:\n",
    "        if usersDoAgree(labels):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return performMajorityVote(msmarco_label,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usersDoAgree(labels):\n",
    "    if len(set(labels)) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performMajorityVote(msmarco_label,labels):\n",
    "    count_votes = Counter(labels)\n",
    "    majority_label = msmarco_label\n",
    "    if (len(labels) % 2) == 0:\n",
    "        vote_threshold = int(len(labels)/2)\n",
    "        for label,votes in count_votes.items():\n",
    "            if votes > vote_threshold:\n",
    "                majority_label = label\n",
    "    else:\n",
    "        vote_threshold = int(np.ceil(len(labels)/2))\n",
    "        for label, votes in count_votes.items():\n",
    "            if votes >= vote_threshold:\n",
    "                majority_label = label\n",
    "    return majority_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id in query_ids:\n",
    "    df = dataframes[query_id]\n",
    "    agreement_labels = []\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    for index, row in df.iterrows():\n",
    "        user_labels = row[getListUserLabelColumns(nr_assessors)].values\n",
    "        binary_labels = makeBinary(user_labels)\n",
    "        agreement_label = getAgreementLabel(row['msmarco_binary'],binary_labels)\n",
    "        agreement_labels.append(agreement_label)\n",
    "    df['agreement_label'] = agreement_labels\n",
    "    dataframes[query_id] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thesis Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section creates the dataset that is used for my thesis.\n",
    "\n",
    "We need to check if the agreement labels specify the msmarco relevant passage as relevant as well. If not we remove this query from the dataset. The subjects did not label the msmarco relevant passage as relevant. If I then manually label this passage as relevant I am denying the assessments of the assessors. This is why it is better to leave these cases out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_2_remove = []\n",
    "for query_id in query_ids:\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        df = dataframes[query_id]\n",
    "        idx = df.index[(df['msmarco_binary'] == 1) & (df['agreement_label'] == 0)]\n",
    "        if not (idx.values.size == 0):\n",
    "            queries_2_remove.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['540906', '993987', '427323']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_2_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 queries for which is the case that the subjects did not label the msmarco relevant passage as relevant. So these queries will be left out of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to get rid of all queries for which is the case that (after majority voting) only have the msmarco passage as relevant. We want to get rid of those queries as the do not provide any changes to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_agreement_data = {}\n",
    "for query_id in query_ids:\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        df = dataframes[query_id]\n",
    "        nr_relevant = df['agreement_label'].sum()\n",
    "        query_agreement_data[query_id] = nr_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id, nr_relevant_passages in query_agreement_data.items():\n",
    "    if nr_relevant_passages < 2:\n",
    "        if not query_id in queries_2_remove:\n",
    "            queries_2_remove.append(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['540906', '993987', '427323', '335710']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_2_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id in queries_2_remove:\n",
    "    query_ids.remove(query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create the actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_queries = []\n",
    "relevant_passages = []\n",
    "counter = 0\n",
    "for query_id in query_ids:\n",
    "    nr_assessors = assessor_data[query_id]\n",
    "    if nr_assessors >= 3:\n",
    "        counter += 1\n",
    "        df = dataframes[query_id]\n",
    "        relevance_df = df[df['agreement_label'] == 1]\n",
    "        relevant_queries = relevant_queries + relevance_df['query_id'].values.tolist()\n",
    "        relevant_passages = relevant_passages + relevance_df['passageid'].values.tolist()\n",
    "output_df = pd.DataFrame()\n",
    "output_df['query_id'] = relevant_queries\n",
    "output_df['label1'] = 0\n",
    "output_df['passage_id'] = relevant_passages\n",
    "output_df['label2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('thesis_dataset_binary_threshold2.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
